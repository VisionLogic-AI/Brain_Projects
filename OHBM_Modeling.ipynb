{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OHBM Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNunZsKWLJek7It5NmUc8rw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VisionLogic-AI/Brain_Projects/blob/master/OHBM_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_3leyLa441E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "18be2f7f-748c-4157-fac1-2499caf5c262"
      },
      "source": [
        "!wget -nc https://storage.googleapis.com/ohbm-dl-lindsay-data/trunc_data.pkl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-18 14:55:35--  https://storage.googleapis.com/ohbm-dl-lindsay-data/trunc_data.pkl\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 2404:6800:4008:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 157200207 (150M) [application/octet-stream]\n",
            "Saving to: ‘trunc_data.pkl’\n",
            "\n",
            "trunc_data.pkl      100%[===================>] 149.92M  68.0MB/s    in 2.2s    \n",
            "\n",
            "2020-05-18 14:55:38 (68.0 MB/s) - ‘trunc_data.pkl’ saved [157200207/157200207]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2_qMdkq7aJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8c076aa-9f45-4430-82d6-bb8df2ae80b5"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/arokem/2019-OHBM-DL-educourse-Lindsay/master/mnistData.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-18 14:55:48--  https://raw.githubusercontent.com/arokem/2019-OHBM-DL-educourse-Lindsay/master/mnistData.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1954 (1.9K) [text/plain]\n",
            "Saving to: ‘mnistData.py’\n",
            "\n",
            "\rmnistData.py          0%[                    ]       0  --.-KB/s               \rmnistData.py        100%[===================>]   1.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-18 14:55:48 (30.3 MB/s) - ‘mnistData.py’ saved [1954/1954]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "157Db3e07p7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f39ed79-272a-4b9d-9933-1fc00d2bea88"
      },
      "source": [
        "#use tensorflow version 1.x and not 2.x\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_w0Xyuh70tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mnistData as mnist\n",
        "\n",
        "np.random.seed(234)\n",
        "\n",
        "batch_size= 128     #number of training images for each batch\n",
        "im_size= 28    #the images are 28x28 pixels\n",
        "num_classes= 10    #there are 10 digit classes\n",
        "\n",
        "data= mnist.DataObject(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWm92Y3n8dYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#these functions create weight and bias variations for the layers\n",
        "def weight_variable(shape, vname):\n",
        "  initial= tf.truncated_normal(shape, stddev= 0.05)\n",
        "  return tf.Variable(initial, name= vname)\n",
        "\n",
        "def bias_variable(shape, vname):\n",
        "  initial= tf.constant(0.0, shape= shape)\n",
        "  return tf.Variable(initial, name=vname)\n",
        "\n",
        "def attn_input(vals, shape):\n",
        "  if len(shape)==4:\n",
        "    evals= tf.expand_dims(tf.expand_dims(tf.expand_dims(vals,0),0),0)\n",
        "  else:\n",
        "    evals= tf.expand_dims(vals, 0)\n",
        "\n",
        "    shape[-1]= 1\n",
        "    return tf.tile(evals, shape)\n",
        "\n",
        "#The following functions create the different kinds of layers that will make up the network.\n",
        "#In tensorflow, networks are represented as graphs, with nodes representing different computations.\n",
        "def conv_layer(conv_input, filt_shape, TCs, conv_num):\n",
        "  w_conv= weight_variable(filt_shape, 'conv_w'+str(conv_num))\n",
        "  b_conv= bias_variable([filt_shape[-1]], 'conv_b'+str(conv_num))\n",
        "  h_conv= tf.nn.relu(tf.nn.conv2d(conv_input, w_conv, strides=[1,1,1,1], padding= 'SAME') + b_conv, 'conv'+str(conv_num))\n",
        "  out_shape= h_conv.get_shape().as_list()\n",
        "  attn= attn_input(TCs, out_shape)\n",
        "  return tf.multiply(h_conv, attn)\n",
        "\n",
        "def pooling_layer(pool_input, ksize, pool_num):\n",
        "  h_pool= tf.nn.max_pool(pool_input, ksize=ksize, strides=[1,2,2,1], padding= 'SAME', name= 'pool'+str(pool_num))\n",
        "  return h_pool\n",
        "\n",
        "def fullyconnected_layer(fc_input, inp_units, out_size, TCs, fc_num):\n",
        "  inp_shape= tf.shape(fc_input);\n",
        "  inp_dimens= tf.shape(inp_shape);\n",
        "\n",
        "  w_fc= weight_variable([inp_units, out_size], 'fc_w'+str(fc_num))\n",
        "  b_fc= bias_variable([out_size], 'fc_b'+str(fc_num))\n",
        "\n",
        "  inp_flat= tf.reshape(fc_input, [batch_size, -1])\n",
        "  h_fc= tf.nn.relu(tf.matmul(inp_flat, w_fc) + b_fc, 'fc'+str(fc_num))\n",
        "  out_shape= h_fc.get_shape().as_list()\n",
        "\n",
        "  attn= attn_input(TCs, out_shape)\n",
        "  h_fc_attn= tf.multiply(h_fc, attn)\n",
        "  h_fc_drop= tf.nn.dropout(h_fc_attn, keep_prob)\n",
        "\n",
        "  return h_fc_drop\n",
        "\n",
        "def readout_layer(ro_input, inp_units, out_size):\n",
        "  inp_shape= tf.shape(ro_input);\n",
        "  inp_dimens= tf.shape(inp_shape);\n",
        "\n",
        "  w_fc= weight_variable([inp_units, out_size], 'ro_w')\n",
        "  b_fc= bias_variable([out_size], 'ro_b')\n",
        "\n",
        "  inp_flat= tf.reshape(ro_input, [batch_size, -1])\n",
        "  h_fc= tf.nn.relu(tf.matmul(inp_flat, w_fc) + b_fc, 'ro')\n",
        "  return h_fc\n",
        "\n",
        "\n",
        "#In tensorflow, inouts are given as place holders. This takes the place of the actual images that will be used when we wrun the network later\n",
        "x= tf.placeholder(tf.float32, [batch_size, im_size**2])\n",
        "x_image= tf.reshape(x, [-1, im_size,im_size, 1])\n",
        "keep_prob= tf.placeholder(tf.float32)  #for adding dropout\n",
        "\n",
        "y_int= tf.placeholder(tf.int32, [batch_size])   #this is the placeholder for the output that is the digit label for each image\n",
        "y_= tf.one_hot(y_int, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3PK2DY3BidP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build our CNN model\n",
        "FM_1= 32   #number of features at each layer\n",
        "FM_2= 64\n",
        "FM_3= 1024\n",
        "\n",
        "#these will be filled with digit specific attention values:\n",
        "tvals_1= tf.placeholder(tf.float32, [FM_1])\n",
        "tvals_2= tf.placeholder(tf.float32, [FM_2])\n",
        "tvals_3= tf.placeholder(tf.float32, [FM_3])\n",
        "\n",
        "#Building the network\n",
        "conv_1= conv_layer(x_image, [3,3,1, FM_1], tvals_1, 1)\n",
        "pool_1= pooling_layer(conv_1, [1,3,3,1], 1)\n",
        "conv_2= conv_layer(pool_1, [3,3, FM_1, FM_2], tvals_2, 2)\n",
        "pool_2= pooling_layer(conv_2, [1,3,3,1], 2)\n",
        "flatten_units= np.prod(pool_2.get_shape().as_list()[1:])\n",
        "fc_1= fullyconnected_layer(pool_2, flatten_units, FM_3, tvals_3,1)\n",
        "readout= readout_layer(fc_1, FM_3, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmg26v6tEsQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#comparing the activity of the final with the true digit label using cross entropy loss:\n",
        "cross_entropy= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= readout, labels= y_))\n",
        "\n",
        "#using the ADAM optimizer that implements a modified backpropagation\n",
        "train_step= tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "\n",
        "#calculating how mahy images were classifed correctly:\n",
        "preds= tf.argmax(readout, 1)\n",
        "correct_prediction= tf.wqual(preds, tf.argmax(y_1))\n",
        "accuracy= tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "#what the images look like:\n",
        "plt.figure()\n",
        "for i in range(10):\n",
        "  plt.subplot(2, 5, i + 1)\n",
        "  plt.imshow(np.reshape(data.val_images[i, :], [im_size, im_size]), cmap= 'bone')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVTmb9hyPkrf",
        "colab_type": "text"
      },
      "source": [
        "#Train Model\n",
        "The tensorflow graph is now built. The next thing to do is start a tensorflow session and begin training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjST2lLLPevb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start tf session and initialize variables\n",
        "sess= tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_intializer())\n",
        "\n",
        "val_acc= 0.; val_curve= [];  #we will keep track of the validation set accuracy\n",
        "cur_batch= -1 #this is the current batch number we are on\n",
        "\n",
        "#getting the validatio set\n",
        "ims_val= data.val_images[0:batch_size,:]\n",
        "labs_val= data.val_labels[0:batch_size]\n",
        "\n",
        "#training loop:\n",
        "#the attention values are set to 1 during training\n",
        "while (val_acc < .95 and cur_batch < 3000):\n",
        "  cur_batch+=1\n",
        "  ims, labs= data.get_trainbatch()\n",
        "  train_step.run(feed_dict= {x: ims, y_int: labs, tvals_1: np.ones(FM_1), tvals_2: np.ones(FM_2), tvals_3: np.ones(CFM_3), keep_prob: .5})\n",
        "\n",
        "  if cur_batch%50==0:\n",
        "    print('Batch ' + str(cur_batch))\n",
        "    \n",
        "    #calcuate validation accuracy\n",
        "    val_acc= accuracy.eval(feed_dict= {x:ims_val, y_int:labs_val, tvals_1: np.ones(FM_1), tvals_2: np.ones(FM_2), tvals_3: np.ones(FM_3), keep_prob: 1.})\n",
        "    val_curve.append(val_acc)\n",
        "\n",
        "\n",
        "#plot the validation accuracy as a function of training batch\n",
        "plt.plot(np.arange(len(val_curve))*100, val_curve)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb2d0tXHYPQX",
        "colab_type": "text"
      },
      "source": [
        "#Now Run the Network with Attention\n",
        "For this we need to make noisy images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbRN_8UwYX6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_imageset(ims, labs, dig, noise_sc1=1.):\n",
        "  dig_infs= np.where(labs==dig)[0][0: batch_size//2]\n",
        "  nondig_inds= np.where(labs!=dig)[0][-0: batch_size//2]\n",
        "  inds= np.concatenate([dig_infs, nondig_inds])\n",
        "  dig_ims= ims[inds,:]\n",
        "  dig_ims += np.random.randn(dig_ims.shape[0], dig_ims.shape[1])*noise_sc1\n",
        "  return dig_ims\n",
        "\n",
        "def make_tvals(TCs, dig):\n",
        "  #this uses tuning information to determine how to scale the networks activity\n",
        "  tvals= TCs[dig,:]\n",
        "  tvals[np.isnan(tvals)]= 0\n",
        "  tvals +=1\n",
        "  tvals[tvals<0]= 0\n",
        "  return tvals_1\n",
        "\n",
        "attn_dig= 4    #digit attention is applied to\n",
        "attn_layer= 2   #layer attention is applied to\n",
        "\n",
        "#getting noisy test set\n",
        "ims_noise= make_imageset(data.val_images[batch_size:, :], data.val_labels[batch_size:], attn_dig, noise_sc1= 1.5)\n",
        "\n",
        "#example if noisy images...first half contain the attended digit, second half do not)\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(np.reshape(ims_noise[0,:], [im_size, im_size]), cmap= 'bone'); plt.show()\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(np.reshape(ims_noise[batch_size//2,:], [im_size, im_size]), cmap= 'bone'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe2NeK6oe5rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In this loop, attention is applied with increasing strength, and true and false positive rates are calculated\n",
        "strngs= np.arange(0, 1, .1)\n",
        "TPs= [];, FPs= []\n",
        "for strng in strngs:\n",
        "  tvals= make_tvals(tuning_curves[attn_layer-1]*strng, attn_dig)\n",
        "  if attn_layer== 1:\n",
        "    predictions= preds.eval(feed_dict= {x: ims_noise, tvals_1: tvals, tvals_2: np.ones(FM_2), tvals_3:np.ones(FM_3), keep-prob: 1.})\n",
        "\n",
        "  elif attn_layer ==2:\n",
        "    predictions= preds.eval(feed_dict= {x: ims_noise, tvals_1: no.ones(FM_1), tvals_2: tvals, tvals_3: np.ones(FM_3), keep_prob: 1.})\n",
        "  \n",
        "  elif attn_layer ==3: \n",
        "    predictions= preds.eval(feed_dict= {x:ims_noise, tvals_1: np.ones(FM_1), tvals_2: np.ones(FM_2), tvals_3: tvals, keep_prob: 1.})\n",
        "\n",
        "  TPs.append(np.sum(predictions[0: batch_size//2]==attn_dig)/(len(predictions)//2))\n",
        "  Fps.append(np.sum(predictions[batch_size//2:]==attn_dig)/len(predictions)//2)\n",
        "\n",
        "  print(strng, predictions)\n",
        "\n",
        "#Results of applying attention on performance:\n",
        "plt.figure(figsize= (12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(strngs, TPs)\n",
        "plt.plot(strngs, FPs)\n",
        "plt.xlabel('Strength Attention')\n",
        "plt.ylabel('Rate')\n",
        "plt.legend(['Truw +', 'False +'])\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(strngs, TPs,-TPs[0])\n",
        "plt.plot(strngs, FPs-FPs[0])\n",
        "plt.xlabel('Strength of Attention')\n",
        "plt.ylabel('Rate Change')\n",
        "plt.legend(['True +', 'False +'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}